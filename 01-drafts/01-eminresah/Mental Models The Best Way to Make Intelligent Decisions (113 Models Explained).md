Mental Models: The Best Way to Make Intelligent Decisions (113 Models Explained)

https://fs.blog/mental-models/

## Düşünce Modelleri: 

### [The Map is Not the Territory](https://fs.blog/2015/11/map-and-territory/) 

### [Circle of Competence](https://fs.blog/2013/12/mental-model-circle-of-competence/) 

- But as Buffett so eloquently put it, we do not necessarily need to understand
  these more esoteric areas to invest capital. Far more important is to honestly
  define what we do know and stick to those areas. Our circle of competence can
  be widened, but only slowly and over time. Mistakes are most often made when
  straying from this discipline.
 
- You have to figure out what your own aptitudes are. If you play games where
  other people have the aptitudes and you don’t, you’re going to lose. And
  that’s as close to certain as any prediction that you can make. You have to
  figure out where you’ve got an edge. And you’ve got to play within your own
  circle of competence.
 
### [First Principles Reasoning](htps://fs.blog/2018/04/first-principles/)

- So much of what we believe is based on some authority figure telling us that
  something is true. As children, we learn to stop questioning when we’re told
  “Because I said so.” (More on this later.) As adults, we learn to stop
  questioning when people say “Because that’s how it works.” The implicit
  message is “understanding be damned — shut up and stop bothering me.” It’s not
  intentional or personal. OK, sometimes it’s personal, but most of the time,
  it’s not.

- If you outright reject dogma, you often become a problem: a student who is
  always pestering the teacher. A kid who is always asking questions and never
  allowing you to cook dinner in peace. An employee who is always slowing things
  down by asking why.

- First-principles reasoning cuts through dogma and removes the blinders. We can
  see the world as it is and see what is possible.

- When it comes down to it, everything that is not a law of nature is just a
  shared belief. Money is a shared belief. So is a border. So are bitcoins. The
  list goes on.

### [Thought Experiment](https://fs.blog/2017/06/thought-experiment-how-einstein-solved-difficult-problems/)

- Thought experiments are natural extension of curiosity. 

Some key types of thought experiments:

- **Prefactual** – Involving potential future outcomes. E.g. ‘What will X cause
  to happen?’

- **Counterfactual** – Contradicting known facts. E.g. ‘If Y happened instead of
  X, what would be the outcome?’

- **Semi-factual** – Contemplating how a different past could have lead to the
  same present. E.g. ‘If Y had happened instead of X, would the outcome be the
  same?’

- **Prediction** – Theorising future outcomes based on existing data.
  Predictions may involve mental or computational models. E.g. ‘If X continues
  to happen, what will the outcome be in one year?’

- **Hindcasting** - Running a prediction in reverse to see if it forecasts an
  event which has already happened. E.g. ‘X happened, could Y have predicted
  it?’

- **Retrodiction** – Moving backwards from an event to discover the root cause.
  Retrodiction is often used for problem solving and prevention purposes. E.g.
  ‘What caused X? How can we prevent it from happening again?’

- **Backcasting** – Considering a specific future outcome, then working forwards
  from the present to deduce its causes. E.g. ‘If X happens in one year, what
  would have caused it?’

### [Second Order Thinking](https://fs.blog/2016/04/second-order-thinking/)

In his exceptional book, The Most Important Thing, Howard Marks explains the
concept of second-order thinking, which he calls second-level thinking.

>    First-level thinking is simplistic and superficial, and just about everyone
>    can do it (a bad sign for anything involving an attempt at superiority).
>    All the first-level thinker needs is an opinion about the future, as in
>    “The outlook for the company is favorable, meaning the stock will go up.”
>    Second-level thinking is deep, complex and convoluted.


First-order thinking is fast and easy. It happens when we look for something
that only solves the immediate problem without considering the consequences. For
example, you can think of this as I’m hungry so let’s eat a chocolate bar.

Second-order thinking is more deliberate. It is thinking in terms of
interactions and time, understanding that despite our intentions our
interventions often cause harm. Second order thinkers ask themselves the
question “And then what?” This means thinking about the consequences of
repeatedly eating a chocolate bar when you are hungry and using that to inform
your decision.

### [Probabilistic Thinking](https://fs.blog/2018/05/probabilistic-thinking/)

#### Bayesian Thinking

The core of Bayesian thinking (or Bayesian updating, as it can be called) is
this: given that we have limited but useful information about the world, and are
constantly encountering new information, we should probably take into account
what we already know when we learn something new. As much of it as possible.
Bayesian thinking allows us to use all relevant prior information in making
decisions. Statisticians might call it a base rate, taking in outside
information about past situations like the one you’re in.

Consider the headline “Violent Stabbings on the Rise.” Without Bayesian
thinking, you might become genuinely afraid because your chances of being a
victim of assault or murder is higher than it was a few months ago. But a
Bayesian approach will have you putting this information into the context of
what you already know about violent crime.

#### Fat Tails

The bell curve is great because it’s easy to understand and easy to use. Its
technical name is “normal distribution.” If we know we are in a bell curve
situation, we can quickly identify our parameters and plan for the most likely
outcomes.

At first glance they seem similar enough. Common outcomes cluster together,
creating a wave. The difference is in the tails. In a bell curve the extremes
are predictable. There can only be so much deviation from the mean. In a
fat-tailed curve there is no real cap on extreme events.

The more extreme events that are possible, the longer the tails of the curve
get. Any one extreme event is still unlikely, but the sheer number of options
means that we can’t rely on the most common outcomes as representing the
average. The more extreme events that are possible, the higher the probability
that one of them will occur. Crazy things are definitely going to happen, and we
have no way of identifying when.

The important thing is not to sit down and imagine every possible scenario in
the tail (by definition, it is impossible) but to deal with fat-tailed domains
in the correct way: by positioning ourselves to survive or even benefit from the
wildly unpredictable future, by being the only ones thinking correctly and
planning for a world we don’t fully understand.

#### Asymmetry

Another common asymmetry is people’s ability to estimate the effect of traffic
on travel time. How often do you leave “on time” and arrive 20% early? Almost
never? How often do you leave “on time” and arrive 20% late? All the time?
Exactly. Your estimation errors are asymmetric, skewing in a single direction.
This is often the case with probabilistic decision-making.[2]

Far more probability estimates are wrong on the “over-optimistic” side than the
“under-optimistic” side. You’ll rarely read about an investor who aimed for 25%
annual return rates who subsequently earned 40% over a long period of time. You
can throw a dart at the Wall Street Journal and hit the names of lots of
investors who aim for 25% per annum with each investment and end up closer to
10%.
