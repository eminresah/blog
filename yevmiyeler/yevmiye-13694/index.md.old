Title: Yevmiye 13694
Author: Emin Reşah
Date:  2017-01-11 00:37:35
Dp: 13694
Status: published
Image: /img/header-94.jpg

[Superintelligence: The Idea That Smart People Refuse to Think About](https://hackernoon.com/superintelligence-the-idea-that-smart-people-refuse-to-think-about-be9dae3b8d62?gi=230f62806c39) (Superzeka:
Zeki insanların düşünmeyi reddettiği fikir) diye bir yazı okudum. Yapay Zeka'nın
insan türünü yok edecek derecede tehlikeli olabileceğini, önceki doktorada aynı
konuda (analoji)
çalıştığım
[bir araştırmacının yazısını](http://www.foundalis.com/soc/why_no_more_Bongard.html) okuduktan
sonra iyice kanaat etmiştim ancak bu konu artık ciddi manada tartışılan bir konu
haline geldi. Yazı da bu konuda ileri sürülen, *Yapay Zeka'nın tehlikeleri
abartılıyor*
diyen [başka bir yazıya](http://idlewords.com/talks/superintelligence.htm) cevap
olarak yazılmış.

Benim için *Superintelligence* yazısının vurucu kısmı şu:

> If it takes 20 years to train an AI to super-human level, once this training
> is done it can be reused to manufacture many copies of that AI. Thus we are
> left with a species that is smarter than us and has a replication rate much
> faster than us and is in our same cognitive niche. Once trained, its mind can
> be copied instantly, and its hardware manufactured at scale. The history of
> natural selection suggests this will not end well.

> Eğer bir Yapay Zeka'yı insan üstü seviyede eğitmek 20 seneyi alacaksa, bir
> defa bu eğitim tamamlandığında onu sınırsız sayıda kopyasını yapmak mümkün
> olacak. Bu durumda karşımızda bizden daha zeki ve *üreme* kapasitesi bizden
> binlerce kez daha hızlı bir türle karşı karşıya kalacağız. Bir defa çalışmaya
> başladığında, zihni anında kopyalanmaya hazır ve bedeni bizden katkat hızlı
> üretilebilir olacak. Doğal seleksiyonun tarihi bunun (bizim açımızdan) pek de
> iyi bitmeyeceğini söylüyor.

Bu kanaat bende de mevcut. Asıl işim olan bu ve benzeri konular üzerinde
çalışırken insan türünün sonunu getirmeye *yarayacak* bir iş yapıp yapmadığımı
sorgulamaya başladım. Teknolojinin her durumda daha iyi olduğunu düşünmüyorum,
bununla beraber insanların artık teknolojiden ayrılabilir, onsuz yaşayabilir
olduklarını da sanmıyorum.

Ara bir yol mümkün mü? Yapay zekayı insan üstü seviyelere çıkarmadan insana
yarayacak seviyede tutmak? Muhtemelen bu zamana kadar gerçekleştirilmiş en
önemli *düşünce birliği* bu iş için gerekli ve teknoloji ilerlediğinde
zihinlerini makinelere kopyalayabileceklerini düşününen *transhumanist*
akıldaneleri muteber olduğu sürece böyle bir birliğin mümkün olduğunu
sanmıyorum. Yapay zeka araştırmaları (diyelim) nükleer araştırmalar kadar pahalı
da değil ve bunların insan üstü seviyelere çıkması, merdivenaltı bir
laboratuvarda da gerçekleşebilir.

Yapay zekanın doğal yollardan, kendini sınırlaması da zor görünüyor çünkü,
diyelim, insanlar için Mars'ta kendine yeterli bir üs kurmak belki yüzyıllar
alacakken, robotlar için (insanın ihtiyaç duyduklarına ihtiyaçları olmadığından)
bu süre hayli kısa. Onların önünde kolayca yayılabilecekleri bir galaksi, bizim
elimizde dengesi ne zaman bozulacağını bilmediğimiz bir gezegen. Bahis oynuyor
olsam, hangisine oynayacağımı biliyorum.



